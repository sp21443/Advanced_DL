{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "LXCd4BCYIwVK"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers, models\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "# VGG 16\n",
    "from tensorflow.keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RAZzD2P_I3ln",
    "outputId": "db4f7fa4-dfc9-4fa6-debd-93176b5a69b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 90s 1us/step\n",
      "170508288/170498071 [==============================] - 91s 1us/step\n",
      "Train: X=(50000, 32, 32, 3), y=(50000, 1)\n",
      "Test: X=(10000, 32, 32, 3), y=(10000, 1)\n",
      "Number of classes=10\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.keras.datasets.cifar10\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer','dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "(train_images0, train_labels0), (test_images0, test_labels0) = dataset.load_data()\n",
    "\n",
    "print('Train: X=%s, y=%s' % (train_images0.shape, train_labels0.shape))\n",
    "print('Test: X=%s, y=%s' % (test_images0.shape, test_labels0.shape))\n",
    "\n",
    "train_labels = train_labels0.reshape(-1)\n",
    "test_labels = test_labels0.reshape(-1)\n",
    "\n",
    "num_classification_categories = len(class_names)\n",
    "print('Number of classes=%d' % num_classification_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7fmICmFOI_v6",
    "outputId": "66b424c0-c4fe-47f7-ef3a-7ce4f7703d21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "train_images = tf.keras.applications.vgg19.preprocess_input(train_images0)\n",
    "test_images = tf.keras.applications.vgg19.preprocess_input(test_images0)\n",
    "\n",
    "print(train_images.shape, test_images.shape)\n",
    "\n",
    "input_shape = train_images.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CjFONQlNJOkl",
    "outputId": "0a5a5f31-1590-4507-bead-856249d895d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 14:03:34.680509: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-04-01 14:03:34.680658: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 32, 32, 64)        1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 4, 4, 512)         1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input = layers.Input(shape=input_shape)\n",
    "model_ = VGG16(weights='imagenet', include_top=False, input_tensor=input)\n",
    "# include_top=False means that we exclude the last (top) layers \n",
    "# (which are responsible for classifying ImageNET)\n",
    "# So we're only loading the convolutional part of the network (see summary below)\n",
    "model_.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "hpqkm6_oJeWO"
   },
   "outputs": [],
   "source": [
    "for layer in model_.layers: \n",
    "  layer.trainable = False\n",
    "\n",
    "# Use the generated model \n",
    "last_layer = model_.output  # these are the features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZEgHvWDRJgC1",
    "outputId": "97d447ab-d8ed-4c77-f8d7-32b95118e4d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 32, 32, 64)        1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 4, 4, 512)         1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 128)               32896     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,880,202\n",
      "Trainable params: 165,514\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Now we are going to add the fully connected layers onto the model.\n",
    "x = layers.Flatten()(last_layer)\n",
    "\n",
    "# Add fully-connected layers for classification (remember that we need to flatten the features first)\n",
    "# TO DO: THIS IS OUR CLASSIFIER. WITH THE CONFIGURATION I'M GIVING YOU, YOUR MODEL WILL OVERFIT TERRIBLY. YOUR JOB IS TO EDIT THESE LAYERS SO THAT THE VALIDATION ACCURACY IS >0.65 AND THERE'S NO OVERFITTING\n",
    "# HINTS: add a Dropout layer between 'fc1' and 'fc2' and reduce the number of neurons in  'fc1'.\n",
    "# ----- beginning of classifier\n",
    "x = layers.Dense(256, activation='relu', name='fc1')(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "x = layers.Dense(128, activation='relu', name='fc2')(x)\n",
    "# ----- end of classifier\n",
    "\n",
    "prediction = layers.Dense(num_classification_categories, activation='softmax')(x)\n",
    "\n",
    "# What does the model look like now?\n",
    "model = models.Model(inputs=input, outputs=prediction)\n",
    "model.summary()  # TO DO:  you will need this for the Moodle quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TTejmh3KJiyE",
    "outputId": "b0334ceb-698f-4331-e73a-51963b818997"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 14:03:36.645106: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 14:03:36.923098: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - ETA: 0s - loss: 1.9159 - accuracy: 0.4939"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 14:03:59.384637: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 27s 60ms/step - loss: 1.9159 - accuracy: 0.4939 - val_loss: 1.1660 - val_accuracy: 0.5923\n",
      "Epoch 2/5\n",
      "391/391 [==============================] - 23s 58ms/step - loss: 1.1145 - accuracy: 0.6160 - val_loss: 1.0528 - val_accuracy: 0.6351\n",
      "Epoch 3/5\n",
      "391/391 [==============================] - 24s 62ms/step - loss: 0.9905 - accuracy: 0.6522 - val_loss: 1.0170 - val_accuracy: 0.6524\n",
      "Epoch 4/5\n",
      "391/391 [==============================] - 24s 62ms/step - loss: 0.9053 - accuracy: 0.6832 - val_loss: 0.9935 - val_accuracy: 0.6602\n",
      "Epoch 5/5\n",
      "391/391 [==============================] - 24s 63ms/step - loss: 0.8418 - accuracy: 0.7042 - val_loss: 0.9871 - val_accuracy: 0.6625\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.SparseCategoricalCrossentropy(), \n",
    "                 optimizer=keras.optimizers.Adam(), \n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "my_callbacks = [ModelCheckpoint(filepath='vgg16_model_featureExtraction.h5', save_best_only=True)]  # DON'T CHANGE THIS LINE\n",
    "\n",
    "# You can change the number of epochs, batch_size...\n",
    "history = model.fit(train_images, train_labels, batch_size=128,\n",
    "                       epochs=5,\n",
    "                       validation_data=(test_images, test_labels),\n",
    "                       callbacks=my_callbacks)\n",
    "np.save('history_featureExtraction.npy', [history.history['accuracy'], history.history['val_accuracy']])  # DON'T CHANGE THIS LINE; you'll need this for the Moodle quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "3-z06OrTKot9"
   },
   "outputs": [],
   "source": [
    "# We specify the shape of our inputs\n",
    "input = layers.Input(shape=input_shape)\n",
    "\n",
    "# Load VGG16 again\n",
    "model_ = VGG16(weights='imagenet', include_top=False, input_tensor=input)\n",
    "#print(model_.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 32, 32, 64)        1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 4, 4, 512)         1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 128)               65664     \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,789,258\n",
      "Trainable params: 14,789,258\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# get last layer so we can add our classifier on top again\n",
    "last_layer = model_.output\n",
    "\n",
    "# Flatten\n",
    "x = layers.Flatten()(last_layer)\n",
    "\n",
    "# Add your classifier\n",
    "# ----- beginning of classifier\n",
    "# TO DO: COPY HERE THE CLASSIFIER CONFIGURATION THAT WORKED FOR YOU IN THE FEATURE EXTRACTION TASK\n",
    "x = layers.Dense(128, activation='relu', name='fc1')(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "x = layers.Dense(64, activation='relu', name='fc2')(x)\n",
    "\n",
    "# ----- end of classifier\n",
    "\n",
    "prediction = layers.Dense(num_classification_categories, activation='softmax')(x)\n",
    "\n",
    "# Create model\n",
    "model = models.Model(input, prediction)\n",
    "\n",
    "\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_4 False\n",
      "block1_conv1 False\n",
      "block1_conv2 False\n",
      "block1_pool False\n",
      "block2_conv1 False\n",
      "block2_conv2 False\n",
      "block2_pool False\n",
      "block3_conv1 False\n",
      "block3_conv2 False\n",
      "block3_conv3 False\n",
      "block3_pool False\n",
      "block4_conv1 False\n",
      "block4_conv2 False\n",
      "block4_conv3 False\n",
      "block4_pool False\n",
      "block5_conv1 False\n",
      "block5_conv2 False\n",
      "block5_conv3 False\n",
      "block5_pool False\n",
      "flatten_5 True\n",
      "fc1 True\n",
      "dropout_8 True\n",
      "fc2 True\n",
      "dense_5 True\n"
     ]
    }
   ],
   "source": [
    "# We first need to freeze all the layers except for our classifier (as we did for the feature extraction approach)\n",
    "\n",
    "# Choose the layers which are updated while training\n",
    "LAYERS_TO_FREEZE = len(model_.layers)  # DON'T CHANGE THIS\n",
    "for layer in model.layers[:LAYERS_TO_FREEZE]:\n",
    "\tlayer.trainable = False\n",
    "for layer in model.layers[LAYERS_TO_FREEZE:]:\n",
    "  layer.trainable = True\n",
    "\n",
    "for i, layer in enumerate(model.layers):\n",
    "  print(layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 15:22:22.246508: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - ETA: 0s - loss: 1.5932 - accuracy: 0.4403"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 15:22:42.391378: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 22s 27ms/step - loss: 1.5932 - accuracy: 0.4403 - val_loss: 1.2296 - val_accuracy: 0.5681\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 21s 27ms/step - loss: 1.1977 - accuracy: 0.5725 - val_loss: 1.1024 - val_accuracy: 0.6211\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 21s 27ms/step - loss: 1.0370 - accuracy: 0.6333 - val_loss: 0.8989 - val_accuracy: 0.6820\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 21s 27ms/step - loss: 0.9398 - accuracy: 0.6704 - val_loss: 0.8225 - val_accuracy: 0.7118\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 21s 27ms/step - loss: 0.8678 - accuracy: 0.6988 - val_loss: 0.7585 - val_accuracy: 0.7341\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 21s 26ms/step - loss: 0.8078 - accuracy: 0.7200 - val_loss: 0.7275 - val_accuracy: 0.7455\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 21s 26ms/step - loss: 0.7667 - accuracy: 0.7332 - val_loss: 0.7065 - val_accuracy: 0.7553\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 21s 27ms/step - loss: 0.7247 - accuracy: 0.7468 - val_loss: 0.6720 - val_accuracy: 0.7679\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 21s 27ms/step - loss: 0.6958 - accuracy: 0.7574 - val_loss: 0.6961 - val_accuracy: 0.7662\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 21s 27ms/step - loss: 0.6669 - accuracy: 0.7707 - val_loss: 0.6920 - val_accuracy: 0.7719\n"
     ]
    }
   ],
   "source": [
    "cnn = models.Sequential([\n",
    "    layers.Conv2D(filters=64,\n",
    "          kernel_size=(3, 3),\n",
    "          activation='relu',\n",
    "          input_shape=(32, 32, 3)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Dropout(0.3),\n",
    "\n",
    "    layers.Conv2D(filters=128,\n",
    "          kernel_size=(3, 3),\n",
    "          activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Dropout(0.3),\n",
    "\n",
    "    layers.Conv2D(filters=256,\n",
    "          kernel_size=(3, 3),\n",
    "          activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Dropout(0.3),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Stop training when the monitored metric has stopped improving.\n",
    "early_stop = EarlyStopping(monitor='val_loss',\n",
    "                           mode='min',\n",
    "                           verbose=1,\n",
    "                           patience=10)\n",
    "\n",
    "cnn.compile(optimizer='adam',\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "history = cnn.fit(train_images,\n",
    "                  train_labels,\n",
    "                  epochs=10,\n",
    "                  batch_size=64,\n",
    "                  callbacks=[early_stop],\n",
    "                  validation_data=(test_images, test_labels))\n",
    "\n",
    "np.save('history_fineTuning_1.npy', [history.history['accuracy'], history.history['val_accuracy']])  # don't change this line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 21s 27ms/step - loss: 0.6466 - accuracy: 0.7758 - val_loss: 0.6401 - val_accuracy: 0.7793\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 20s 26ms/step - loss: 0.6201 - accuracy: 0.7844 - val_loss: 0.6629 - val_accuracy: 0.7803\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 21s 26ms/step - loss: 0.5936 - accuracy: 0.7940 - val_loss: 0.6522 - val_accuracy: 0.7827\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 21s 26ms/step - loss: 0.5782 - accuracy: 0.8010 - val_loss: 0.6246 - val_accuracy: 0.7920\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 21s 27ms/step - loss: 0.5574 - accuracy: 0.8049 - val_loss: 0.6490 - val_accuracy: 0.7849\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 21s 26ms/step - loss: 0.5419 - accuracy: 0.8109 - val_loss: 0.6045 - val_accuracy: 0.8016\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 20s 26ms/step - loss: 0.5217 - accuracy: 0.8186 - val_loss: 0.6215 - val_accuracy: 0.7985\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 20s 26ms/step - loss: 0.5070 - accuracy: 0.8247 - val_loss: 0.6333 - val_accuracy: 0.7962\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 21s 26ms/step - loss: 0.4906 - accuracy: 0.8303 - val_loss: 0.6028 - val_accuracy: 0.8084\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 21s 26ms/step - loss: 0.4818 - accuracy: 0.8319 - val_loss: 0.6171 - val_accuracy: 0.8065\n"
     ]
    }
   ],
   "source": [
    "history = cnn.fit(train_images,\n",
    "                  train_labels,\n",
    "                  epochs=10,\n",
    "                  batch_size=64,\n",
    "                  callbacks=[early_stop],\n",
    "                  validation_data=(test_images, test_labels))\n",
    "\n",
    "np.save('history_fineTuning_2.npy', [history.history['accuracy'], history.history['val_accuracy']])  # don't change this line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 15:09:43.208819: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3124/3125 [============================>.] - ETA: 0s - loss: 1.5281 - accuracy: 0.5220"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 15:10:14.155012: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 38s 12ms/step - loss: 1.5279 - accuracy: 0.5221 - val_loss: 1.1225 - val_accuracy: 0.6119\n",
      "Epoch 2/5\n",
      "3125/3125 [==============================] - 36s 11ms/step - loss: 1.0702 - accuracy: 0.6304 - val_loss: 1.0377 - val_accuracy: 0.6465\n",
      "Epoch 3/5\n",
      "3125/3125 [==============================] - 36s 12ms/step - loss: 0.9909 - accuracy: 0.6580 - val_loss: 1.0243 - val_accuracy: 0.6510\n",
      "Epoch 4/5\n",
      "3125/3125 [==============================] - 36s 12ms/step - loss: 0.9380 - accuracy: 0.6770 - val_loss: 1.0298 - val_accuracy: 0.6462\n",
      "Epoch 5/5\n",
      "3125/3125 [==============================] - 36s 12ms/step - loss: 0.8917 - accuracy: 0.6933 - val_loss: 1.0009 - val_accuracy: 0.6620\n"
     ]
    }
   ],
   "source": [
    "# Train the model (remember that for now we're only training the top layers -- i.e., the ones closest to the output, not the convolutional part!)\n",
    "\n",
    "# For this first part we train for a few epochs only\n",
    "\n",
    "cnn.compile(loss=keras.losses.SparseCategoricalCrossentropy(), \n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "my_callbacks = [ModelCheckpoint(filepath='vgg16_model_fineTuning.h5', save_best_only=True)]  # don't change this line\n",
    "\n",
    "history = model.fit(train_images, train_labels, \n",
    "                    batch_size=16,\n",
    "                    epochs=5,  # this number should be small-ish\n",
    "                    validation_data=(test_images, test_labels),\n",
    "                    callbacks=my_callbacks)\n",
    "\n",
    "np.save('history_fineTuning_1.npy', [history.history['accuracy'], history.history['val_accuracy']])  # don't change this line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2f4843fa0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Have a look at the training graphs. \n",
    "# When your validation accuracy is >0.8, you can upload it to the Moodle quiz.\n",
    "\n",
    "epochs = range(1, len(history.history['accuracy']) + 1)\n",
    "plt.plot(epochs, history.history['accuracy'], label='train_accuracy')\n",
    "plt.plot(epochs, history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlim([1, None])\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Advanced DL.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
